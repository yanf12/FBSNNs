{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting import newfig, savefig\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from IPython.display import display, clear_output\n",
    "class neural_net(nn.Module):\n",
    "    def __init__(self, NL, NN):\n",
    "        self.NL = NL\n",
    "        self.NN = NN\n",
    "        super(neural_net, self).__init__()\n",
    "        self.input_layer = nn.Linear(1, NL)\n",
    "        self.hidden_layer = nn.Linear(NN, int(NN/2))\n",
    "        self.output_layer = nn.Linear(int(NN/2), 1)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = torch.tanh(self.input_layer(x))\n",
    "        out = torch.tanh(self.hidden_layer(out))\n",
    "        out_final = self.output_layer(out)\n",
    "        return out_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, x):\n",
    "        super(PINN, self).__init__()\n",
    "        self.x = x\n",
    "        N = 20000\n",
    "        net = neural_net(4, 20)\n",
    "        self.mse = nn.MSELoss(reduction='mean')\n",
    "        self.optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "        x_0 = torch.zeros(2000, 1)\n",
    "        y_0 = net(self.x_0)\n",
    "\n",
    "\n",
    "    def ode(self):\n",
    "        y = self.net(self.x)\n",
    "        y_x = torch.autograd.grad(y, self.x, grad_outputs=torch.ones_like(self.net(self.x)), create_graph=True)[0]\n",
    "        return y-y_x\n",
    "\n",
    "\n",
    "    def loss_function(self):\n",
    "        y = self.net(self.x)\n",
    "        y_x = torch.autograd.grad(y, self.x, grad_outputs=torch.ones_like(self.net(self.x)), create_graph=True)[0]\n",
    "        y_xx = torch.autograd.grad(y_x, self.x, grad_outputs=torch.ones_like(self.net(self.x)), create_graph=True)[0]\n",
    "        return self.mse(y_xx, -self.ode())\n",
    "\n",
    "    def train(self, epochs=10000):\n",
    "        self.net.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss_function(self.x, self.net)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}