{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x= torch.tensor([2,3]).float()\n",
    "x.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2., 3.], requires_grad=True)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "y = x**2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4., 9.], grad_fn=<PowBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([4., 6.]),)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(y.sum(), x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class neural_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(neural_net, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(1, 256)\n",
    "        self.fc_2 = nn.Linear(256, 256)\n",
    "        self.fc_3 = nn.Linear(256, 256)\n",
    "        self.fc_4 = nn.Linear(256, 256)\n",
    "        self.out = nn.Linear(256,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            torch.nn.init.xavier_uniform(self.fc_1.weight)\n",
    "            torch.nn.init.xavier_uniform(self.fc_2.weight)\n",
    "            torch.nn.init.xavier_uniform(self.fc_3.weight)\n",
    "            torch.nn.init.xavier_uniform(self.fc_4.weight)\n",
    "\n",
    "    def forward(self, state, train=False):\n",
    "        state = torch.sin(self.fc_1(state))\n",
    "        state = torch.sin(self.fc_2(state))\n",
    "        # state = torch.sin(self.fc_3(state))\n",
    "        # state = torch.sin(self.fc_4(state))\n",
    "        fn_u = self.out(state)\n",
    "        return fn_u"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.3010], grad_fn=<AddBackward0>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_nn.forward(torch.tensor([10]).float())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\751256153.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc_1.weight)\n",
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\751256153.py:16: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc_2.weight)\n",
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\751256153.py:17: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc_3.weight)\n",
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\751256153.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc_4.weight)\n"
     ]
    }
   ],
   "source": [
    "example_nn = neural_net()\n",
    "optimizer = optim.Adam(example_nn.parameters(), lr=0.1)\n",
    "x = torch.linspace(0, 10, 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "\n",
    "y_pred = []\n",
    "for x_ in x:\n",
    "    y_pred.append(example_nn.forward(torch.tensor([x_]).float()).detach().numpy()[0])\n",
    "y_target = x**2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(2030.3531, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\4084923133.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = example_nn.forward(torch.tensor(x).float().unsqueeze(-1))\n",
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\4084923133.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_target = torch.tensor(y_target, requires_grad=True).float()\n",
      "C:\\Users\\haoyang\\AppData\\Local\\Temp\\ipykernel_25616\\4084923133.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = torch.mean((y_target - torch.tensor(y_pred))**2)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = example_nn.forward(torch.tensor(x).float().unsqueeze(-1))\n",
    "    y_pred = y_pred.squeeze(1)\n",
    "\n",
    "    y_target = torch.tensor(y_target, requires_grad=True).float()\n",
    "    print(y_target)\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.mean((y_target - torch.tensor(y_pred))**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0000e+00, 1.0203e-02, 4.0812e-02, 9.1827e-02, 1.6325e-01, 2.5508e-01,\n        3.6731e-01, 4.9995e-01, 6.5299e-01, 8.2645e-01, 1.0203e+00, 1.2346e+00,\n        1.4692e+00, 1.7243e+00, 1.9998e+00, 2.2957e+00, 2.6120e+00, 2.9487e+00,\n        3.3058e+00, 3.6833e+00, 4.0812e+00, 4.4995e+00, 4.9383e+00, 5.3974e+00,\n        5.8770e+00, 6.3769e+00, 6.8973e+00, 7.4380e+00, 7.9992e+00, 8.5808e+00,\n        9.1827e+00, 9.8051e+00, 1.0448e+01, 1.1111e+01, 1.1795e+01, 1.2499e+01,\n        1.3223e+01, 1.3968e+01, 1.4733e+01, 1.5519e+01, 1.6325e+01, 1.7151e+01,\n        1.7998e+01, 1.8865e+01, 1.9753e+01, 2.0661e+01, 2.1590e+01, 2.2539e+01,\n        2.3508e+01, 2.4498e+01, 2.5508e+01, 2.6538e+01, 2.7589e+01, 2.8660e+01,\n        2.9752e+01, 3.0864e+01, 3.1997e+01, 3.3150e+01, 3.4323e+01, 3.5517e+01,\n        3.6731e+01, 3.7966e+01, 3.9220e+01, 4.0496e+01, 4.1792e+01, 4.3108e+01,\n        4.4444e+01, 4.5801e+01, 4.7179e+01, 4.8577e+01, 4.9995e+01, 5.1434e+01,\n        5.2893e+01, 5.4372e+01, 5.5872e+01, 5.7392e+01, 5.8933e+01, 6.0494e+01,\n        6.2075e+01, 6.3677e+01, 6.5299e+01, 6.6942e+01, 6.8605e+01, 7.0289e+01,\n        7.1993e+01, 7.3717e+01, 7.5462e+01, 7.7227e+01, 7.9012e+01, 8.0818e+01,\n        8.2645e+01, 8.4491e+01, 8.6359e+01, 8.8246e+01, 9.0154e+01, 9.2082e+01,\n        9.4031e+01, 9.6000e+01, 9.7990e+01, 1.0000e+02], requires_grad=True)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "y_pred = y_pred.squeeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 2.1172e-01,  2.0955e-01,  2.0736e-01,  2.0513e-01,  2.0287e-01,\n         2.0057e-01,  1.9825e-01,  1.9590e-01,  1.9353e-01,  1.9113e-01,\n         1.8870e-01,  1.8625e-01,  1.8377e-01,  1.8128e-01,  1.7876e-01,\n         1.7622e-01,  1.7367e-01,  1.7110e-01,  1.6852e-01,  1.6592e-01,\n         1.6331e-01,  1.6068e-01,  1.5805e-01,  1.5541e-01,  1.5276e-01,\n         1.5010e-01,  1.4744e-01,  1.4478e-01,  1.4211e-01,  1.3945e-01,\n         1.3678e-01,  1.3411e-01,  1.3145e-01,  1.2879e-01,  1.2614e-01,\n         1.2349e-01,  1.2084e-01,  1.1821e-01,  1.1558e-01,  1.1296e-01,\n         1.1036e-01,  1.0776e-01,  1.0518e-01,  1.0261e-01,  1.0005e-01,\n         9.7510e-02,  9.4983e-02,  9.2472e-02,  8.9976e-02,  8.7498e-02,\n         8.5037e-02,  8.2595e-02,  8.0171e-02,  7.7766e-02,  7.5380e-02,\n         7.3014e-02,  7.0669e-02,  6.8344e-02,  6.6040e-02,  6.3758e-02,\n         6.1497e-02,  5.9258e-02,  5.7042e-02,  5.4848e-02,  5.2676e-02,\n         5.0528e-02,  4.8402e-02,  4.6300e-02,  4.4222e-02,  4.2167e-02,\n         4.0136e-02,  3.8129e-02,  3.6146e-02,  3.4187e-02,  3.2253e-02,\n         3.0343e-02,  2.8458e-02,  2.6597e-02,  2.4761e-02,  2.2950e-02,\n         2.1163e-02,  1.9401e-02,  1.7664e-02,  1.5953e-02,  1.4266e-02,\n         1.2604e-02,  1.0967e-02,  9.3553e-03,  7.7685e-03,  6.2067e-03,\n         4.6701e-03,  3.1585e-03,  1.6716e-03,  2.0985e-04, -1.2273e-03,\n        -2.6392e-03, -4.0265e-03, -5.3891e-03, -6.7268e-03, -8.0402e-03],\n       grad_fn=<SqueezeBackward1>)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}